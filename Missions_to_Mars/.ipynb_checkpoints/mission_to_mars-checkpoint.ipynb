{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping - Mission to Mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mac Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## executable path to driver for windows users\n",
    "# executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "# browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#executable path to driver for windows users\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url of page to be scraped \n",
    "url_news = 'https://mars.nasa.gov/news/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visit the url through the spinter module and add 5 sec delay in the execution \n",
    "browser.visit(url_news)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_title = NASA's Perseverance Rover Goes Through Trials by Fire, Ice, Light and Sound \n",
      "news_p = The agency's new Mars rover is put through a series of tests in vacuum chambers, acoustic chambers and more to get ready for the Red Planet.\n"
     ]
    }
   ],
   "source": [
    "# HTML Object\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "# Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text. \n",
    "# Assign the text to variables that you can reference later.\n",
    "\n",
    "news_title = soup.find_all('div', class_='content_title')[1]\n",
    "#used the location for news_title as it was not scraping the \"a\" element of html in the given class.\n",
    "#simply using news_title = soup.find('div', class_='content_title').find('a').text\n",
    "#other way of doing it would be to call the main 'div' for the first news article and then use it to pull title and paragraph\n",
    "#article = soup.find(\"div\", class_='list_text')\n",
    "news_title = news_title.text\n",
    "\n",
    "news_p = soup.find(class_='article_teaser_body').text\n",
    "\n",
    "print(f'news_title = {news_title} \\nnews_p = {news_p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url of page to be scraped \n",
    "url_img = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use splinter to navigate the site\n",
    "browser.visit(url_img)\n",
    "time.sleep(5)\n",
    "html1 = browser.html\n",
    "soup1 = BeautifulSoup(html1, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA19347-1920x1200.jpg\n"
     ]
    }
   ],
   "source": [
    "# find the image url for the current Featured Mars Image and assign the url string to a variable called featured_image_url.\n",
    "featured_image = soup1.find('article')['style'].replace(\"background-image: url('\",'').replace(\"');\",'')\n",
    "featured_image\n",
    "\n",
    "featured_image_url = (f'https://www.jpl.nasa.gov{featured_image}')\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Mars Weather twitter account and scrape the latest Mars weather tweet from the page. \n",
    "url_weather = 'https://twitter.com/marswxreport?lang=en'\n",
    "browser.visit(url_weather)\n",
    "time.sleep(5)\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sol 524 (2020-05-18) low -92.5ºC (-134.4ºF) high 0.5ºC (32.9ºF) winds from the SW at 4.8 m/s (10.7 mph) gusting to 15.3 m/s (34.3 mph) pressure at 7.00 hPa1318\n"
     ]
    }
   ],
   "source": [
    "# Save the tweet text for the weather report as a variable called mars_weather.\n",
    "#scrape the mars twitter page\n",
    "mars_weather = soup.find_all(\"article\", attrs={\"role\":\"article\"})[0].text\n",
    "#Replace all \\n with space for continuity\n",
    "mars_weather = mars_weather.replace('\\n', ' ')\n",
    "#Split to get rid of the initial part of the statement \"Mars Weather@MarsWxReport·9h InSight \"\n",
    "mars_weather= mars_weather.split(\"InSight \")[1]\n",
    "#mars_weather = mars_weather[40:]\n",
    "#print out the latest weather tweet\n",
    "print(mars_weather)\n",
    "\n",
    "# mars_weather = soup.find_all(\"article\", attrs={\"role\":\"article\"})\n",
    "# mars_weather = lets_try[0].find_all(\"div\")[0].find_all(\"div\")[3]\n",
    "# mars_weather = lets_try.find_all(\"div\")[9].text\n",
    "# mars_weather\n",
    "\n",
    "# Twitter frequently changes how information is presented on their website. If you are having difficulty getting the correct html tag data, consider researching Regular Expression Patterns and how they can be used in combination with the .find() method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Equatorial Diameter:</td>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Polar Diameter:</td>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.39 × 10^23 kg (0.11 Earths)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Moons:</td>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Orbit Distance:</td>\n",
       "      <td>227,943,824 km (1.38 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Orbit Period:</td>\n",
       "      <td>687 days (1.9 years)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Surface Temperature:</td>\n",
       "      <td>-87 to -5 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>First Record:</td>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Recorded By:</td>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Values\n",
       "Description                                        \n",
       "Equatorial Diameter:                       6,792 km\n",
       "Polar Diameter:                            6,752 km\n",
       "Mass:                 6.39 × 10^23 kg (0.11 Earths)\n",
       "Moons:                          2 (Phobos & Deimos)\n",
       "Orbit Distance:            227,943,824 km (1.38 AU)\n",
       "Orbit Period:                  687 days (1.9 years)\n",
       "Surface Temperature:                   -87 to -5 °C\n",
       "First Record:                     2nd millennium BC\n",
       "Recorded By:                   Egyptian astronomers"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# * Visit the Mars Facts webpage and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "url_facts = 'https://space-facts.com/mars/'\n",
    "browser.visit(url_facts)\n",
    "# * Use Pandas to convert the data to a HTML table string.\n",
    "table = pd.read_html(url_facts)[0]\n",
    "#rename columns\n",
    "table.columns=['Description', 'Values']\n",
    "#set index\n",
    "table.set_index('Description', inplace = True)\n",
    "#convert to html\n",
    "x = table.to_html()\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Visit the USGS Astrogeology site to obtain high resolution images for each of Mars hemispheres.\n",
    "astro_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "browser.visit(astro_url)\n",
    "time.sleep(5)\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# * You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "hemispheres = soup.find_all(class_=\"description\")\n",
    "#print(hemispheres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere ',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/39d3266553462198bd2fbc4d18fbed17_cerberus_enhanced.tif_thumb.png'},\n",
       " {'title': 'Schiaparelli Hemisphere ',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/08eac6e22c07fb1fe72223a79252de20_schiaparelli_enhanced.tif_thumb.png'},\n",
       " {'title': 'Syrtis Major Hemisphere ',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/55a0a1e2796313fdeafb17c35925e8ac_syrtis_major_enhanced.tif_thumb.png'},\n",
       " {'title': 'Valles Marineris Hemisphere ',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/4e59980c1c57f89c680c0e1ccabbeff1_valles_marineris_enhanced.tif_thumb.png'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hemisphere_image_urls = []\n",
    "\n",
    "base_url = 'https://astrogeology.usgs.gov'\n",
    "\n",
    "for hemisphere in hemispheres:\n",
    "    #scrape and store the title of the hemispheres. Replace the word enhanced\n",
    "    title = hemisphere.find('h3').text\n",
    "    title = title.replace('Enhanced', '')\n",
    "\n",
    "    #scrape and store the partial url and visit the full url link and parse the HTML\n",
    "    url = hemisphere.find('a')['href']\n",
    "    browser.visit(base_url+url)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    #get the partial url of the image and join with the base url\n",
    "    image_url = soup.find('img',class_='thumb')['src']\n",
    "    img_url = base_url+image_url\n",
    "\n",
    "    #Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n",
    "    hemisphere_image_urls.append({\"title\":title, \"img_url\":img_url})\n",
    "\n",
    "hemisphere_image_urls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
